<p align="center">
  <img src="https://img.shields.io/badge/PyTorch-2.0+-ee4c2c?style=for-the-badge&logo=pytorch&logoColor=white" alt="PyTorch">
  <img src="https://img.shields.io/badge/Next.js-14+-000000?style=for-the-badge&logo=nextdotjs&logoColor=white" alt="Next.js">
  <img src="https://img.shields.io/badge/FastAPI-0.100+-009688?style=for-the-badge&logo=fastapi&logoColor=white" alt="FastAPI">
  <img src="https://img.shields.io/badge/License-MIT-blue?style=for-the-badge" alt="License">
</p>

<h1 align="center">ğŸ«€ PULSE</h1>
<h3 align="center"><b>P</b>PG-based <b>U</b>ncertainty-aware <b>L</b>earning for <b>S</b>ignal <b>E</b>stimation</h3>

<p align="center">
  <em>A robust deep learning system for heart rate estimation from PPG signals with conformal prediction for uncertainty quantification.</em>
</p>

---

## ğŸ“‹ Overview

**PULSE** addresses critical challenges in wearable heart rate monitoring by developing robust deep learning models that work reliably on noisy, real-world PPG (Photoplethysmography) signals.

### The Challenge
Traditional approaches fail on noisy data because they:
- âŒ Exclude "difficult" subjects from training
- âŒ Filter out low-quality signal windows
- âŒ Report inflated accuracy metrics

### Our Solution
We developed an end-to-end learning approach that:
- âœ… Trains on **ALL subjects** including noisy data
- âœ… Uses **16-second windows** for robust rhythm detection
- âœ… Provides **uncertainty estimates** via Conformal Prediction

---

## ğŸ—ï¸ Architecture Evolution

We iteratively improved our approach through three phases:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ARCHITECTURE EVOLUTION                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Phase 1: Transformer        Phase 2: ResNet-1D       Phase 3: Hybrid       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Self-Attention â”‚         â”‚   Conv Blocks   â”‚      â”‚   CNN + LSTM    â”‚   â”‚
â”‚  â”‚    Encoder      â”‚   â†’     â”‚   + Residual    â”‚  â†’   â”‚  + Attention    â”‚   â”‚
â”‚  â”‚   (11.11 BPM)   â”‚         â”‚   (5.93 BPM)    â”‚      â”‚   (5.40 BPM)    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â”‚  Issue: Overfitting          47% Improvement!         BEST MODEL - Custom   â”‚
â”‚  to motion noise             via signal filtering     architecture design   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Results

### Performance Comparison

| Model | Architecture | MAE (BPM) | Improvement | Parameters |
|-------|--------------|-----------|-------------|------------|
| TransPPG | Transformer Encoder | 11.11 | Baseline | ~3.2M |
| ResNet-1D | 4 Residual Blocks | 5.93 | **47% â†“** | ~2.0M |
| **AttentionCNNLSTM** | CNN + Bi-LSTM + Attention | **5.40** | **51% â†“** | ~1.5M |

### Key Features
- ğŸ¯ **5.40 BPM** Mean Absolute Error (approaching clinical-grade)
- ğŸ“ˆ **90%+ Coverage** with Conformal Prediction intervals
- âš¡ **Real-time Inference** on consumer GPUs

---

## ğŸ”§ Installation

### Prerequisites
- Python 3.10+
- CUDA 11.8+ (for GPU training)
- Node.js 18+ (for web app)

### Setup

```bash
# Clone the repository
git clone https://github.com/Akhil-0412/PULSE.git
cd PULSE

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
.\venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt
```

---

## ğŸš€ Usage

### Training Models

```bash
# Train Transformer (Phase 1)
python src/training/train_transformer.py

# Train ResNet-1D (Phase 2)
python src/training/train_resnet.py

# Train AttentionCNNLSTM (Phase 3 - Best)
python src/training/train_hybrid.py
```

### Running the Web App

```bash
# Start backend
cd webapp/backend
uvicorn main:app --reload --port 8000

# Start frontend (in new terminal)
cd frontend
npm install
npm run dev
```

Visit `http://localhost:3000` to explore the interactive dashboard.

---

## ğŸ“ Project Structure

```
PULSE/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ transformer.py        # Phase 1: TransPPG
â”‚   â”‚   â”œâ”€â”€ resnet1d.py           # Phase 2: ResNet-1D
â”‚   â”‚   â””â”€â”€ attention_cnn_lstm.py # Phase 3: Custom Hybrid
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ train_transformer.py
â”‚   â”‚   â”œâ”€â”€ train_resnet.py
â”‚   â”‚   â””â”€â”€ train_hybrid.py
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ resnet1d/
â”‚   â”œâ”€â”€ hybrid/
â”‚   â””â”€â”€ visualizations/
â”œâ”€â”€ frontend/                     # Next.js dashboard
â”œâ”€â”€ webapp/backend/               # FastAPI server
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ§  Model Architecture: AttentionCNNLSTM

```
Input: 4 channels Ã— 1600 samples (16 seconds @ 100Hz)
                    â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     CNN Feature Extraction    â”‚
    â”‚   Conv1d(4â†’64â†’128â†’256)        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      Bi-LSTM Temporal         â”‚
    â”‚    LSTM(256â†’128, bidir)       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    Attention + Regression     â”‚
    â”‚   Dense(256â†’64â†’1)             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
            Heart Rate (BPM)
            + Uncertainty (Â±BPM)
```

---

## ğŸ“š Dataset

Uses the **PhysioNet Pulse Transit Time PPG Dataset v1.1.0**:
- 22 healthy subjects
- 4-channel PPG + 3-axis accelerometry
- Ground truth ECG-derived heart rate

> âš ï¸ Dataset files not included. Download from [PhysioNet](https://physionet.org/).

---

## ğŸ™ Acknowledgments

- **Dataset**: PhysioNet PTT-PPG Dataset
- **Frameworks**: PyTorch, FastAPI, Next.js, Recharts

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

---

<p align="center">
  <b>PULSE</b> â€” PPG-based Uncertainty-aware Learning for Signal Estimation
</p>
