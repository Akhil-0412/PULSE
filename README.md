<p align="center">
  <img src="https://img.shields.io/badge/PyTorch-2.0+-ee4c2c?style=for-the-badge&logo=pytorch&logoColor=white" alt="PyTorch">
  <img src="https://img.shields.io/badge/Next.js-14+-000000?style=for-the-badge&logo=nextdotjs&logoColor=white" alt="Next.js">
  <img src="https://img.shields.io/badge/FastAPI-0.100+-009688?style=for-the-badge&logo=fastapi&logoColor=white" alt="FastAPI">
  <img src="https://img.shields.io/badge/License-MIT-blue?style=for-the-badge" alt="License">
</p>

<h1 align="center">ğŸ«€ PulseGuard</h1>
<h3 align="center">Advancing Wearable Health Tech: Deep Learning and Uncertainty-Aware Heart Rate Prediction</h3>

<p align="center">
  <em>A robust PPG-based heart rate estimation system using deep learning with conformal prediction for uncertainty quantification.</em>
</p>

---

## ğŸ“‹ Overview

This project addresses critical challenges in wearable heart rate monitoring by developing **robust deep learning models** that work reliably on noisy, real-world PPG (Photoplethysmography) signals.

### The Challenge
Traditional approaches fail on noisy data because they:
- âŒ Exclude "difficult" subjects from training
- âŒ Filter out low-quality signal windows
- âŒ Report inflated accuracy metrics

### Our Solution
We developed an end-to-end learning approach that:
- âœ… Trains on **ALL subjects** including noisy data
- âœ… Uses **16-second windows** for robust rhythm detection
- âœ… Provides **uncertainty estimates** via Conformal Prediction

---

## ğŸ—ï¸ Architecture Evolution

We iteratively improved our approach through three phases:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ARCHITECTURE EVOLUTION                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Phase 1: Transformer        Phase 2: ResNet-1D       Phase 3: Hybrid       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Self-Attention â”‚         â”‚   Conv Blocks   â”‚      â”‚   CNN + LSTM    â”‚   â”‚
â”‚  â”‚    Encoder      â”‚   â†’     â”‚   + Residual    â”‚  â†’   â”‚  + Attention    â”‚   â”‚
â”‚  â”‚   (11.11 BPM)   â”‚         â”‚   (5.93 BPM)    â”‚      â”‚   (5.40 BPM)    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â”‚  Issue: Overfitting          47% Improvement!         BEST MODEL - Custom   â”‚
â”‚  to motion noise             via signal filtering     architecture design   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Results

### Performance Comparison

| Model | Architecture | MAE (BPM) | Improvement | Parameters |
|-------|--------------|-----------|-------------|------------|
| TransPPG | Transformer Encoder | 11.11 | Baseline | ~3.2M |
| ResNet-1D | 4 Residual Blocks | 5.93 | **47% â†“** | ~2.0M |
| **AttentionCNNLSTM** | CNN + Bi-LSTM + Attention | **5.40** | **51% â†“** | ~1.5M |

### Key Features
- ğŸ¯ **5.40 BPM** Mean Absolute Error (approaching clinical-grade)
- ğŸ“ˆ **90%+ Coverage** with Conformal Prediction intervals
- âš¡ **Real-time Inference** on consumer GPUs

---

## ğŸ”§ Installation

### Prerequisites
- Python 3.10+
- CUDA 11.8+ (for GPU training)
- Node.js 18+ (for web app)

### Setup

```bash
# Clone the repository
git clone https://github.com/yourusername/PPG_Project_Recreation.git
cd PPG_Project_Recreation

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
.\venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Download dataset (PhysioNet)
# Place in data/physionet/
```

---

## ğŸš€ Usage

### Training Models

```bash
# Train Transformer (Phase 1)
python src/training/train_transformer.py

# Train ResNet-1D (Phase 2)
python src/training/train_resnet.py

# Train AttentionCNNLSTM (Phase 3 - Best)
python src/training/train_hybrid.py
```

### Running the Web App

```bash
# Start backend
cd webapp/backend
uvicorn main:app --reload --port 8000

# Start frontend (in new terminal)
cd frontend
npm install
npm run dev
```

Visit `http://localhost:3000` to explore the interactive dashboard.

---

## ğŸ“ Project Structure

```
PPG_Project_Recreation/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ transformer.py        # Phase 1: TransPPG
â”‚   â”‚   â”œâ”€â”€ resnet1d.py           # Phase 2: ResNet-1D
â”‚   â”‚   â””â”€â”€ attention_cnn_lstm.py # Phase 3: Custom Hybrid
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ train_transformer.py
â”‚   â”‚   â”œâ”€â”€ train_resnet.py
â”‚   â”‚   â””â”€â”€ train_hybrid.py
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ preprocess_experiment.py
â”‚   â”‚   â””â”€â”€ preprocess_real.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ check_results.py
â”‚       â”œâ”€â”€ visualize.py
â”‚       â””â”€â”€ verify_loso.py
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ resnet1d/
â”‚   â”‚   â””â”€â”€ cnn_results.npy
â”‚   â”œâ”€â”€ hybrid/
â”‚   â”‚   â””â”€â”€ hybrid_results.npy
â”‚   â””â”€â”€ visualizations/
â”‚       â”œâ”€â”€ mae_ranking.png
â”‚       â””â”€â”€ subjects/
â”œâ”€â”€ webapp/
â”‚   â”œâ”€â”€ frontend/                 # Next.js dashboard
â”‚   â””â”€â”€ backend/                  # FastAPI server
â”œâ”€â”€ data/                         # Datasets (gitignored)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ§  Model Architecture: AttentionCNNLSTM

Our custom hybrid architecture combines the best of CNNs and RNNs:

```
Input: 4 channels Ã— 1600 samples (16 seconds @ 100Hz)
                    â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     CNN Feature Extraction    â”‚
    â”‚   Conv1d(4â†’64) + BN + ReLU    â”‚
    â”‚   Conv1d(64â†’128) + BN + ReLU  â”‚
    â”‚   Conv1d(128â†’256) + BN + ReLU â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ (256 Ã— 100)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      Bi-LSTM Temporal         â”‚
    â”‚    LSTM(256â†’128, bidir)       â”‚
    â”‚     Hidden: 256 features      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    Attention + Regression     â”‚
    â”‚   Multi-Head Self-Attention   â”‚
    â”‚   Dense(256â†’64) + Dense(64â†’1) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
            Heart Rate (BPM)
            + Uncertainty (Â±BPM)
```

---

## ğŸ“š Dataset

This project uses the **PhysioNet Pulse Transit Time PPG Dataset v1.1.0**:
- 22 healthy subjects
- 4-channel PPG + 3-axis accelerometry
- Ground truth ECG-derived heart rate

> âš ï¸ **Note**: Dataset files are not included in this repository due to size. Download from [PhysioNet](https://physionet.org/).

---

## ğŸ™ Acknowledgments

- **Dataset**: PhysioNet PTT-PPG Dataset
- **Frameworks**: PyTorch, FastAPI, Next.js, Recharts
- **Methodology**: Conformal Prediction for uncertainty quantification

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

<p align="center">
  Made with â¤ï¸ for advancing wearable health technology
</p>
